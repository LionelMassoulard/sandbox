{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reseau de Neuronnes avec tensorflow keras\n",
    "Dans ce TP nous allons apprendre à nous servir de réseaux de neuronnes sur des images.\n",
    "Nous reprendrons la classique base MNIST\n",
    "\n",
    "### 0. Installer tensorflow 2 et vérifier la version\n",
    "vérifier la version en faisant : \n",
    "Nous voudrons une version >= 2.0.0 pour profiter des dernières avancées de tensorflow et keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Chargée les données MNIST :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Re-scaler les images pour avoir des valeurs entre 0 et 1 (Regarder la valeur max et min des datas)\n",
    "#### 3. Ajouter un 4ème axes aux données : cet axe correspond au \"channel\" que l'on ajoutera pour être plus proche de données en plusieurs couleurs (avec 3 channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a channels dimension\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Extraire un petit batch de train (20 observations) : ce batch nous servira a effectuer quelques tests par la suite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-13986d104ada>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-13986d104ada>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    images, labels = pass # complete here\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "images, labels = pass # complete here\n",
    "assert images.shape == (20, 28, 28, 1)\n",
    "assert labels.shape == (20,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Grapher ces quelques images. On affichera par exemple le label en titre du plot\n",
    "On pourra utiliser pour cela matplotlib imshow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Quelle loss et quelle metriques peuvent être à utiliser pour ce problème ?\n",
    "#### 7. Créer votre premier modèle keras. Nous commencerons avec un réseau \"vanille\" avec une seule couche cachée.\n",
    "On utiliser 'Sequential' de keras et nottament les couches Dense et Flatten\n",
    "(A quoi sert la couche 'Flatten' dans ce cas ?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Avant même de compiler et fitter votre modèle, appeler le sur votre batch d'image.\n",
    "#### Nous vérifierons en particulier que :\n",
    "* Le modèle fonctionne\n",
    "* La 'shape' de la sortie\n",
    "* Les valeurs de la sortie ('>=0' et 'sommant à 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model(images)\n",
    "yhat.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Compiler votre modèle en indiquant la loss, la metrique et l'optimizer\n",
    "#### 10. fitter votre modèle pour quelques epochs (3 à 5 environs nous donnerons des premiers résultats)\n",
    "#### 11. Regarder les résultats :\n",
    "* accuracy en train et test\n",
    "* regarder quelques images de test avec leur label et leur prédiction (on ré-utilisera le code de la question 5)\n",
    "* regarder quelques erreurs de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Refaire le même modèle en utilisant l'api model de keras\n",
    "https://keras.io/models/model/\n",
    "\n",
    "Cette façon de définir les modèles keras facilitent la création de modèle avancés :\n",
    " * gan, auto-encoder, ...\n",
    " * multi input et output, ...\n",
    " * transfert learning, ...\n",
    " * ...\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. Rajouter un 'callback' réalisant l'early stopping. On utilsera directement le callback keras EarlyStopping\n",
    "Relancer votre code avec un nombre plus important d'epochs et en utilisant votre callback sur une base de test ou validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nous allons maintenant faire un réseau plus complexe, plus adapté aux images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28,28,1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14.  Avant de fitter ce modèle nous allons nous familiariser avec les opérations en regardant de plus prés les 'shape' après chacune des étapes.\n",
    "\n",
    "Sans éxécuter quoique ce soit, quelle est la taille en sortie des différentes couches :\n",
    " * Après la 1ère convolution\n",
    " * Après la 2ème convolution\n",
    " * Après la couche MaxPooling\n",
    " * Après le Dropout\n",
    " * Après le Flatten,\n",
    " * ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vérifier vos résultats en utilisant des modèles 'partiels'\n",
    "Par exemple : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_partial = Sequential()\n",
    "for i in range(2):\n",
    "    model_partial.add(model.layers[i])\n",
    "\n",
    "model_partial(images).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vérifier vos résultats en regardant model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Fitter ce modèle et comparer les résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 2 (Optional): transfert learning vers 'fashion mnist'\n",
    "#### 1. Charger fashion mnist\n",
    "#### 2. Utiliser votre dernier modèle (entrainé sur MNIST) en vous arrétant avant la dernière couche dense\n",
    "#### 3. On va utiliser la sortie de cette couche comme feature pour entrainer 'fashion mnist'\n",
    "#### 4. Extraire ces features et fitter dans 1er temps des modèles classiques \n",
    "* Regression Logistic\n",
    "* RandomForest\n",
    "\n",
    "#### 5. Comparer les résultats en fittant directement ces modèles sur les données bruts  (après avoir 'applatie' les données)\n",
    "#### 6. Comparer en refitant un réseau nouveau (sans transfert) du même type que le réseau MNIST\n",
    "#### 7. Refaite la comparaison en diminuant le nombre d'échantillons utilisé en train pour fashion MNIST\n",
    "\n",
    "#### 8. Faisons maintenant un réseau de neuronnes complet où les premières couches sont figés (entrainé avec MNIST) mais que l'on ré-apprend la/les dernière(s) couches sur fashion MNIST\n",
    "#### 9. Faites la même chose mais cette fois autorisant les premières couches à être 'fine-tuner'. Ces couches seront ainsi\n",
    " * Initialiser avec leur valeur entrainée sur MNIST\n",
    " * Fine-tuner en utilisant les datas MNIST\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
